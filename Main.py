import os
import asyncio
from typing import Optional, Dict, List
from concurrent.futures import ThreadPoolExecutor
import logging
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper, GoogleSearchAPIWrapper
from langchain_community.callbacks.manager import get_openai_callback
from langchain_core.tools import Tool
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# Changed: Using ChatGroq instead of ChatOpenAI
from langchain_groq import ChatGroq

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BlogGenerator:
    def __init__(
        self,
        groq_api_key: str,  # Changed parameter name
        google_api_key: Optional[str] = None,
        google_cse_id: Optional[str] = None,
        model_name: str = "llama-3.1-8b-instant",  # Changed default model
        temperature: float = 0.7,
        max_tokens: int = 4000
    ):
        """Initialize the blog generator with Groq."""
        # Changed: Using ChatGroq
        self.llm = ChatGroq(
            api_key=groq_api_key,
            model=model_name,
            temperature=temperature,
            max_tokens=max_tokens
        )
        self.tools = self._initialize_tools(google_api_key, google_cse_id)
        logger.info(f"Initialized BlogGenerator with {len(self.tools)} tools")

    def _initialize_tools(self, google_api_key: Optional[str], google_cse_id: Optional[str]) -> List[Tool]:
        """Initialize available tools."""
        tools = []
        wiki_wrapper = WikipediaAPIWrapper(top_k_results=2, doc_content_chars_max=4000)
        wiki_tool = WikipediaQueryRun(api_wrapper=wiki_wrapper)
        tools.append(
            Tool(
                name="Wikipedia",
                func=wiki_tool.run,
                description="Search Wikipedia for factual information."
            )
        )

        if google_api_key and google_cse_id:
            search_wrapper = GoogleSearchAPIWrapper(
                google_api_key=google_api_key,
                google_cse_id=google_cse_id,
                k=5
            )
            tools.append(
                Tool(
                    name="GoogleSearch",
                    func=search_wrapper.run,
                    description="Search Google for real-time data and current events."
                )
            )
        return tools

    async def _generate_section(self, section_name: str, prompt: str) -> str:
        """Generate a single section asynchronously."""
        full_prompt = ChatPromptTemplate.from_template(prompt)
        chain = full_prompt | self.llm | StrOutputParser()
        return await chain.ainvoke({})

    async def _generate_parallel(self, prompts: Dict[str, str]) -> Dict[str, str]:
        """Generate multiple sections in parallel."""
        tasks = [self._generate_section(name, text) for name, text in prompts.items()]
        results = await asyncio.gather(*tasks)
        return dict(zip(prompts.keys(), results))

    def generate_blog(self, topic: str, word_count_target: int = 1500) -> Dict[str, str]:
        """Generate a comprehensive blog post."""
        logger.info(f"Generating blog about: {topic}")

        prompts = {
            "introduction": f"Write a 150-word engaging introduction about '{topic}'.",
            "content": f"Write about '{topic}' in detail (~{word_count_target-300} words). Include facts and examples.",
            "summary": f"Write a short conclusion summarizing key takeaways about '{topic}'."
        }

        try:
            sections = asyncio.run(self._generate_parallel(prompts))
            logger.info("Blog generated successfully!")
        except Exception as e:
            logger.error(f"Error generating blog: {e}")
            raise

        blog_post = self._assemble_blog(topic, sections, word_count_target)
        return {
            "topic": topic,
            "blog": blog_post,
            "sections": sections,
            "metadata": {
                "word_count": len(blog_post.split()),
                "target_word_count": word_count_target
            }
        }

    def _assemble_blog(self, topic: str, sections: Dict[str, str], word_count: int) -> str:
        """Format the final blog nicely."""
        blog = f"""# {topic}

*Target Word Count: {word_count} words*

---

## Introduction
{sections.get('introduction', '')}

---

## Main Content
{sections.get('content', '')}

---

## Conclusion
{sections.get('summary', '')}

---

*Generated by AI Blog Generator*
"""
        return blog


def main():
    """Main entry point."""
    # Changed: Use Groq API Key instead
    GROQ_API_KEY = "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"  
    GOOGLE_API_KEY = "AIzaSyBZb-lC7qK1TzXniM2NpxUXgxjTk7F_7Eo"
    GOOGLE_CSE_ID = os.getenv("GOOGLE_CSE_ID")

    if not GROQ_API_KEY:
        raise ValueError("GROQ_API_KEY must be set.")

    generator = BlogGenerator(
        groq_api_key=GROQ_API_KEY,
        google_api_key=GOOGLE_API_KEY,
        google_cse_id=GOOGLE_CSE_ID
    )

    topic = input("Enter a blog topic: ").strip()
    if not topic:
        print("Error: Topic cannot be empty")
        return

    print("\nGenerating blog post...\n")
    result = generator.generate_blog(topic)
    print(result["blog"])
    print("\n---\nMetadata:", result["metadata"])


if __name__ == "__main__":
    main()
